---
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q2_K.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q2_K.gguf
    sha256: f5c2b30ce6f269fd707baecafaf6d1799dd1b56dd79c53a0d6aa47091f0c9416
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q2_K.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q2_K.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q3_K_L.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q3_K_L.gguf
    sha256: d1b1e855d7ec3ac5d34d56e54970dfbe71d6ea42d9e0b95b4612a5971dee22d4
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q3_K_L.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q3_K_L.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q3_K_M.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q3_K_M.gguf
    sha256: 330ca675dc4e9382adeebaf20854c5809f7cb9e1091f699afe5f4949875ae80e
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q3_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q3_K_M.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q3_K_S.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q3_K_S.gguf
    sha256: 177241447862551d43d5e67805269c72f44ab3b0addfa00d082cd47afbc77550
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q3_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q3_K_S.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q4_0.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q4_0.gguf
    sha256: e67753efc6d209d65a76ddd550cb1390763b8e7f14546adf286be6c882670394
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q4_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q4_0.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q4_K_M.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q4_K_M.gguf
    sha256: 1e76ff5d6d2a86acb72e80893f46966e789c7020b4c181f0eded10d99e461fc3
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q4_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q4_K_M.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q4_K_S.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q4_K_S.gguf
    sha256: c2a8794b213e55c23f89e0f35e6f9cd2f3ba6d6b192b7a067f17a02878365cf9
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q4_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q4_K_S.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q5_0.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q5_0.gguf
    sha256: 7c7b501c831cbfbfa2370a2247dba35594c58142c8b48119302bdd94f1fc8bf5
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q5_0.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q5_0.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q5_K_M.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q5_K_M.gguf
    sha256: 8c1dc48aff68cfa06acd7e7e2d02a3f0d3f25722b0c61b3eb89e3e66dabef1c5
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q5_K_M.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q5_K_M.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
- config_file:
    backend: llama
    context_size: 1024
    parameters:
      model: llama-2-70b-orca-200k.Q5_K_S.gguf
    template:
      chat: Guanaco
      completion: Guanaco
  description: TheBloke/Llama-2-70B-Orca-200k-GGUF - llama configuration
  files:
  - filename: Guanaco.tmpl
    sha256: ac55aec4bc4c77920c5232062d0ab29d09e3466684de80fbf3917c7c028b6f74
    uri: 
      https://raw.githubusercontent.com/go-skynet/model-gallery/main/prompt-templates/Guanaco.tmpl
  - filename: llama-2-70b-orca-200k.Q5_K_S.gguf
    sha256: ecf47d66b379f0af1a353f6a5e8231d284f6f0402efc9a4d4d1901e1bb857896
    uri: 
      https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF/resolve/main/llama-2-70b-orca-200k.Q5_K_S.gguf
  icon: https://huggingface.co/front/assets/huggingface_logo-noborder.svg
  license: llama2
  name: TheBloke__Llama-2-70B-Orca-200k-GGUF__llama-2-70b-orca-200k.Q5_K_S.gguf
  tags:
  - transformers
  - llama
  - llama-2
  - instruct
  - instruction
  - text-generation
  - en
  - license:llama2
  - text-generation-inference
  - region:us
  urls:
  - https://huggingface.co/TheBloke/Llama-2-70B-Orca-200k-GGUF
